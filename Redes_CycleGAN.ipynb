{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg7vN1dnM/cd/KlU8kZqk1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeraldflowers/Deep-Learn-PyTorch/blob/main/Redes_CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc35V1s4LspY",
        "outputId": "5a01f9e9-7d9c-4bbf-cce2-224ae295ad3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/gdrive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZaXKYCwL4lN",
        "outputId": "b26fcb53-6e4a-4e22-ff48-93aa65c59e01"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aitorzip/PyTorch-CycleGAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMGRNx8MJ-N",
        "outputId": "5807285d-bd42-459f-d577-4dc1072c96d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyTorch-CycleGAN' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/gdrive/My Drive/PyTorch-CycleGAN'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_2UvItKMqcc",
        "outputId": "719db31d-559f-4edf-e5bb-6f3c0724d2c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/PyTorch-CycleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "sh ./download_dataset summer2winter_yosemite"
      ],
      "metadata": {
        "id": "PcM0YhmpMzHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv datasets/summer2winter_yosemite /gdrive/My\\ Drive/dl-pytorch/datasets/"
      ],
      "metadata": {
        "id": "_K6HEx9XNO31"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /gdrive/My\\ Drive/dl-pytorch/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NAoIjUqNltx",
        "outputId": "d8b8f1fc-2483-4e58-be61-c1999451821c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64x64_SIGNS  64x64_SIGNS.zip  summer2winter_yosemite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    conv_block = [ nn.ReflectionPad2d(1), #mejor padding, conserva más la distribucion\n",
        "                   nn.Conv2d(in_features, in_features, 3),\n",
        "                   nn.InstanceNorm2d(in_features),\n",
        "                   nn.ReLU(True),\n",
        "                   nn.ReflectionPad2d(1),\n",
        "                   nn.Conv2d(in_features, in_features, 3),\n",
        "                   nn.InstanceNorm2d(in_features)\n",
        "                  ]\n",
        "    self.conv_block = nn.Sequential(*conv_block)\n",
        "  def forward(self, x):\n",
        "    return self.conv_block(x) + x #una idea porderosa\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "Xij5vWjrNqNI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import padding\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    #Bloque Convolucional\n",
        "    model = [ nn.ReflectionPad2d(3),\n",
        "              nn.Conv2d(input_nc, 64, 7),\n",
        "              nn.InstanceNorm2d(64),\n",
        "              nn.ReLU(True)\n",
        "             ]\n",
        "    in_features = 64\n",
        "    out_features = in_features * 2\n",
        "\n",
        "    # Encoding\n",
        "    for _ in range(2):\n",
        "      model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), #Imagen / 2\n",
        "                 nn.InstanceNorm2d(out_features),\n",
        "                 nn.ReLU(True)\n",
        "                ]\n",
        "      in_features = out_features\n",
        "      out_features = in_features * 2\n",
        "\n",
        "    # Transformaciones Residuales\n",
        "\n",
        "    for _ in range(n_residual_blocks):\n",
        "      model += [ResidualBlock(in_features)]\n",
        "\n",
        "    # Decoding\n",
        "\n",
        "    out_features = in_features//2\n",
        "    for _ in range(2):\n",
        "      model += [ nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1), #2*I\n",
        "                 nn.InstanceNorm2d(out_features),\n",
        "                 nn.ReLU(True)\n",
        "                ]\n",
        "      in_features = out_features\n",
        "      out_features = in_features//2\n",
        "    \n",
        "    #Salida\n",
        "    model += [ nn.ReflectionPad2d(3),\n",
        "                nn.Conv2d(64, output_nc, 7),\n",
        "                nn.Tanh()\n",
        "              ]\n",
        "      \n",
        "    self.model = nn.Sequential(*model)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "qd_6jjK4SXRj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  \"PatchGAN: discrimina estilo o textura\"\n",
        "  def __init__(self, input_nc):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    model = [ nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "              nn.LeakyReLU(0.2, inplace=True)\n",
        "             ]\n",
        "\n",
        "    model += [ nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "               nn.InstanceNorm2d(128),\n",
        "               nn.LeakyReLU(0.2, inplace=True)\n",
        "             ]\n",
        "\n",
        "    model += [ nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "               nn.InstanceNorm2d(256),\n",
        "               nn.LeakyReLU(0.2, inplace=True)\n",
        "             ]\n",
        "\n",
        "    model += [ nn.Conv2d(256, 512, 4, padding=1),\n",
        "               nn.InstanceNorm2d(512),\n",
        "               nn.LeakyReLU(0.2, inplace=True)\n",
        "             ]\n",
        "\n",
        "    # Flatten\n",
        "    model += [ nn.Conv2d(512, 1, 4, padding=1)] # I - 1\n",
        "\n",
        "    self.model = nn.Sequential(*model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ],
      "metadata": {
        "id": "KSK6cfx-TGOM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/gdrive/My Drive/dl-pytorch/')"
      ],
      "metadata": {
        "id": "kTFu1V4Jbgp8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visdom"
      ],
      "metadata": {
        "id": "pbqjYGu8cjbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from utils import ReplayBuffer"
      ],
      "metadata": {
        "id": "J8N0QZ81brOC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, base_dir, transform=None, split='train'):\n",
        "    self.transform = transforms.Compose(transform)\n",
        "    self.files_A = sorted(glob.glob(os.path.join(base_dir, '{}/A/*.*'.format(split))))\n",
        "    self.files_B = sorted(glob.glob(os.path.join(base_dir, '{}/B/*.*'.format(split))))\n",
        "\n",
        "  def __len__(self):\n",
        "    return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image_A = self.transform(Image.open(self.files_A[idx]))\n",
        "    image_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B)-1)]))\n",
        "    return {'A': image_A, 'B': image_B}"
      ],
      "metadata": {
        "id": "NmmER4N9cdcs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0\n",
        "n_epochs = 200\n",
        "batch_size = 4\n",
        "lr = 0.0002\n",
        "size = 256\n",
        "input_nc = 3\n",
        "output_nc = 3\n",
        "decay_epoch = 100 #pending\n",
        "\n",
        "cuda = True\n",
        "n_cpu = 8\n",
        "\n",
        "base_dir = '/gdrive/my Drive/dl-pytorch/datasets/summer2winter_yosemit/'\n"
      ],
      "metadata": {
        "id": "jDTDCGvlfFTM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "\n",
        "def weights_init_normal(m):\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "    torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
        "  elif isinstance(m,nn.BatchNorm2d):\n",
        "    torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "    torch.nn.init.constant(m.bias, 0.0)\n",
        "\n",
        "netG_A2B = Generator(input_nc, output_nc)\n",
        "netG_B2A = Generator(input_nc, output_nc)\n",
        "netD_A = Discriminator(input_nc)\n",
        "netD_B = Discriminator(input_nc)\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "if cuda:\n",
        "  netG_A2B.to(device)\n",
        "  netG_B2A.to(device)\n",
        "  netD_A.to(device)\n",
        "  netD_B.to(device)\n",
        "\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                               lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# schedulers (actualizar el learning rate de forma dinamica durante el entrenamiento)\n",
        "\n",
        "class LambdaLR():\n",
        "  def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "    assert ((n_epochs - decay_start_epoch) > 0)\n",
        "    self.n_epochs = n_epochs\n",
        "    self.offset = offset\n",
        "    self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "  def step(self, epoch):\n",
        "    return 1 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "861agdONh0pq",
        "outputId": "b3ee3869-5da5-4413-d154-b4496e177dbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs y targets\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "target_real = Tensor(batch_size).fill_(1.0)\n",
        "target_fake = Tensor(batch_size).fill_(0.0)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# Dataloader\n",
        "\n",
        "transform = [ transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
        "              transforms.RandomCrop(size),\n",
        "              transforms.RandomHorizontalFlip(),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "             ]\n",
        "\n",
        "dataloader = DataLoader(ImageDataset(base_dir, transform=transform),\n",
        "                        batch_size=batch_size, shuffle=True, num_workers=n_cpu, drop_last=True)\n",
        "\n",
        "def Gen_GAN_loss(G, D, real, loss, target_real):\n",
        "  fake = G(real)\n",
        "  pred_fake = D(fake)\n",
        "  L = loss(pred_fake, target_real)\n",
        "  return L, fake\n",
        "\n",
        "def cycle_loss(G1, G2, real, loss):\n",
        "  recovered = G2(G1(real))\n",
        "  L = loss(recovered, real)\n",
        "  return L\n",
        "\n",
        "def identity_loss(G, real, loss):\n",
        "  same = G(real)\n",
        "  L = loss(same, real)\n",
        "  return L\n",
        "\n",
        "def Disc_GAN_loss(D2, fake2, real2, fake_2_buffer, loss, target_real, target_fake):\n",
        "  pred_real = D2(real2)\n",
        "  loss_D2_real = loss(pred_real, target_real)\n",
        "\n",
        "  fake2 = fake_2_buffer.push_and_pop(fake2)\n",
        "  pred_fake = D2(fake2.detach)\n",
        "  loss_D2_fake = loss(pred_fake, target_fake)\n",
        "  loss_D2 = (loss_D2_real + loss_D2_fake) * 0.5\n",
        "  return loss_D2"
      ],
      "metadata": {
        "id": "K4B1qPferm_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB3zNa5It_Lo",
        "outputId": "0c55300a-de9b-4243-83ee-b1643bbd28f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n",
            "Installing collected packages: jedi, livelossplot\n",
            "Successfully installed jedi-0.18.1 livelossplot-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from livelossplot import PlotLosses\n",
        "from utils import Logger\n",
        "\n",
        "logger = Logger(n_epochs, len(dataloader), epoch=epoch)\n",
        "liveloss = PlotLosses"
      ],
      "metadata": {
        "id": "Ugg2pnziuG96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch, n_epochs):\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    real_A = batch['A'].to(device)\n",
        "    real_B = batch['B'].to(device)\n",
        "\n",
        "    # Redes Generativas\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    loss_GAN_A2B, fake_B = Gen_GAN_loss(netG_A2B, netD_B, real_A, criterion_GAN, target_real)\n",
        "    loss_GAN_B2A, fake_A = Gen_GAN_loss(netG_B2A, netD_A, real_B, criterion_GAN, target_real)\n",
        "\n",
        "    loss_cycle_ABA = cycle_loss(netG_A2B, netG_B2A, real_A, criterion_cycle)\n",
        "    loss_cycle_BAB = cycle_loss(netG_B2A, netG_A2B, real_B, criterion_cycle)\n",
        "\n",
        "    loss_identity_A = identity_loss(netG_B2A, real_A, criterion_identity)\n",
        "    loss_identity_B = identity_loss(netG_A2B, real_B, criterion_identity)\n",
        "\n",
        "    loss_G = (loss_GAN_A2B + loss_GAN_B2A) + 10.0*(loss_cycle_ABA + loss_cycle_BAB) + 5 *(loss_identity_A + loss_identity_B)\n",
        "    loss_G.backward()\n",
        "\n",
        "    optimizer_G.step\n",
        "\n",
        "    # Redes Discriminativas\n",
        "    optimizer_D_A.zero_grad()\n",
        "\n",
        "    loss_D_A = Disc_GAN_loss(netD_A, fake_A, real_A, fake_A_buffer, criterion_GAN, target_real, target_fake)\n",
        "    loss_D_A.backward()\n",
        "    optimizer_D_A.step()\n",
        "\n",
        "    optimizer_D_B.zero_grad()\n",
        "\n",
        "    loss_D_B = Disc_GAN_loss(netD_B, fake_B, real_B, fake_A_buffer, criterion_GAN, target_real, target_fake)\n",
        "    loss_D_B.backward()\n",
        "    optimizer_D_B.step()\n",
        "  \n",
        "    log_values = {'loss_G': loss_G,\n",
        "                  'loss_G_identity': (loss_identity_A + loss_identity_B),\n",
        "                  'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
        "                  'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB),\n",
        "                  'loss_D': (loss_D_A + loss_D_B)\n",
        "                  }\n",
        "\n",
        "    logger.log(log_values, images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
        "\n",
        "liveloss.update(log_values)\n",
        "liveloss.draw()\n",
        "\n",
        "  lr_scheduler_G.step()\n",
        "  lr_scheduler_D_A.step()\n",
        "  lr_scheduler_D_B.step()\n"
      ],
      "metadata": {
        "id": "96cHXRcwF2Q6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}